{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset \n",
    "## Sensor Datasets with Feature Extraction\n",
    "Sensor datasets, recorded by various sensors detecting environmental changes, are crucial for real-time monitoring, decision-making, predictive analysis, and automation.\n",
    "\n",
    "##### Types of Sensors\n",
    "*Temperature Sensors*: Measure temperature.\n",
    "*Pressure Sensors*: Detect pressure variations.\n",
    "*Accelerometers and Gyroscopes*: Measure acceleration and orientation.\n",
    "*Proximity and Light Sensors*: Detect object presence and light intensity.\n",
    "*Sound Sensors*: Capture audio signals.\n",
    "*Chemical Sensors*: Monitor environmental changes.\n",
    "*GPS Sensors*: Provide location data.\n",
    "**_Data is not only collected from temperature sensors, but also from other types of sensors that gather information such as text, video, audio, and various environmental parameters._**\n",
    "\n",
    "![Data can exist in any form: text, audio, video, and images](IntroductionImages/TextVideoImageSpeech.JPG)\n",
    "\n",
    "Data can exist in any form: text, audio, video, and images\n",
    "\n",
    "## Feature Extraction\n",
    "Sensor datasets often contain diverse information collected from various types of sensors.Feature extraction transforms raw sensor data into representative features for analysis, improving data interpretation and prepare for machine learning algorithm.\n",
    "_For example_, in the following figure, the activity signal introduced in the above section is converted into a feature vector including mean, variance, skewness, and other features.\n",
    "\n",
    "![Activity signal converted into a feature vector (mean, variance, skewness, etc.](IntroductionImages/Activity_Feature.jpg)\n",
    "\n",
    "Activity signal converted into a feature vector (mean, variance, skewness, etc.\n",
    "\n",
    "### Some Examples of Feature extraction\n",
    "\n",
    "#### Feature Extraction from Text: \n",
    "Feature extraction from text involves converting text data into numerical representations that can be used for machine learning models. One common method is using the Term Frequency-Inverse Document Frequency (TF-IDF) approach.\n",
    "\n",
    "Hereâ€™s a simple explanation and Python code to perform TF-IDF feature extraction:\n",
    "\n",
    "#### Concepts:\n",
    "*Document*: A piece of text. *Corpus*: A collection of documents. *Term Frequency (TF)*: The frequency of a term ð‘¡ in a document ð‘‘. *Inverse Document Frequency (IDF)*: Measures how important a term is in the entire corpus.\n",
    "The TF-IDF value increases with the number of times a term appears in a document but is offset by the frequency of the term in the corpus, to adjust for the fact that some words are generally more common than others.\n",
    "\n",
    "**Steps to Compute TF-IDF:**\n",
    "1-Calculate the Term Frequency (TF) for each term in each document.\n",
    "2-Calculate the Inverse Document Frequency (IDF) for each term.\n",
    "3-Multiply the TF and IDF values to get the TF-IDF score for each term in each document.\n",
    "\n",
    "##### TF-IDF Formula\n",
    "TF-IDF stands for Term Frequency-Inverse Document Frequency. It is a numerical statistic intended to reflect how important a word is to a document in a collection or corpus.\n",
    "\n",
    "##### Term Frequency (TF)\n",
    "The term frequency TF(t,d) is the frequency of term t  in document  d.\n",
    "\n",
    "$$\n",
    "\\text{TF}(t,d) = \\frac{\\text{Number of times term } t \\text{ appears in document } d}{\\text{Total number of terms in document } d}\n",
    "$$\n",
    "\n",
    "#### Inverse Document Frequency (IDF)\n",
    "\n",
    "The inverse document frequency IDF(t,D)  measures how important a term is across the entire corpus D .\n",
    "\n",
    "$$\n",
    "\\text{IDF}(t,D) = \\log \\left( \\frac{N}{|\\{d \\in D : t \\in d\\}|} \\right)\n",
    "$$\n",
    "\n",
    "$$N\\left(x_i, \\mu_c, \\Sigma_c\\right)=\\frac{1}{(2 \\pi)^{\\frac{n}{2}}\\left|\\Sigma_c\\right|^{\\frac{1}{2}}} \\exp \\left(-\\frac{1}{2}\\left(x_i-\\mu_c\\right)^T \\Sigma_c^{-1}\\left(x_i-\\mu_c\\right)\\right)$$\n",
    "\n",
    "Where:\n",
    "-  N is the total number of documents in the corpus. Denumerator is the number of documents where the term  t appears (i.e., the document frequency of the term).\n",
    "\n",
    "#### TF-IDF Score\n",
    "The TF-IDF score for a term  t  in a document d is the product of its TF and IDF values.\n",
    "\n",
    "$$\n",
    "\\text{TF-IDF}(t,d,D) = \\text{TF}(t,d) \\times \\text{IDF}(t,D)\n",
    "$$\n",
    "\n",
    "This formula adjusts the term frequency of a word by how rarely it appears in the entire corpus, emphasizing words that are more unique to specific documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix:\n",
      " [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.37483157 0.         0.\n",
      "  0.         0.         0.55052949 0.         0.         0.\n",
      "  0.         0.         0.         0.37483157 0.         0.\n",
      "  0.         0.         0.         0.24321139 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.37483157 0.         0.         0.37483157 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.27526475\n",
      "  0.        ]\n",
      " [0.37996836 0.         0.27903704 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.37996836\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.32092732 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.24654442 0.37996836 0.\n",
      "  0.         0.         0.         0.         0.         0.37996836\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.27903704\n",
      "  0.32092732]\n",
      " [0.         0.         0.34597941 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.39791937 0.\n",
      "  0.47112464 0.         0.         0.         0.         0.\n",
      "  0.         0.39791937 0.         0.         0.         0.\n",
      "  0.         0.34597941 0.         0.         0.         0.\n",
      "  0.47112464 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.26905631 0.         0.\n",
      "  0.         0.26905631 0.         0.         0.         0.\n",
      "  0.         0.53811262 0.19758666 0.         0.26905631 0.\n",
      "  0.17457857 0.         0.45449848 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.26905631\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.26905631 0.         0.         0.         0.\n",
      "  0.         0.26905631 0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.29057873 0.         0.39568482 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.25674213 0.         0.3342017  0.         0.         0.\n",
      "  0.39568482 0.         0.         0.         0.         0.\n",
      "  0.         0.3342017  0.39568482 0.         0.         0.\n",
      "  0.         0.         0.39568482 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.36866152 0.         0.31137739 0.\n",
      "  0.         0.         0.27073365 0.36866152 0.         0.\n",
      "  0.47841584 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.23920792 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.36866152 0.\n",
      "  0.         0.         0.36866152 0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.34529878\n",
      "  0.22404889 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.34529878 0.         0.         0.\n",
      "  0.         0.29164485 0.         0.34529878 0.34529878 0.\n",
      "  0.         0.         0.         0.         0.         0.34529878\n",
      "  0.34529878 0.         0.         0.         0.         0.25357678\n",
      "  0.29164485]\n",
      " [0.         0.43632467 0.         0.         0.         0.\n",
      "  0.43632467 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.43632467 0.43632467\n",
      "  0.         0.32042338 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.36852676 0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.52173373\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.38314517 0.         0.33852961 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.52173373 0.44066462 0.\n",
      "  0.        ]]\n",
      "\n",
      "Feature Names:\n",
      " ['also' 'although' 'and' 'another' 'breathed' 'brighter' 'clearer'\n",
      " 'creation' 'faith' 'follow' 'for' 'forgive' 'forgiving' 'given' 'god'\n",
      " 'greater' 'has' 'hastened' 'have' 'he' 'him' 'if' 'in' 'interpretation'\n",
      " 'into' 'is' 'lord' 'love' 'may' 'meaning' 'merciful' 'my' 'of' 'pleasure'\n",
      " 'seek' 'sins' 'so' 'soul' 'spirit' 'that' 'those' 'to' 'towards' 'we'\n",
      " 'who' 'without' 'words' 'you' 'your']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"If you love God, follow God so that\",\n",
    "    \"He may also love you and forgive your sins, \",\n",
    "    \"for He is Forgiving and Merciful.\",\n",
    "    \"God has given Him another creation, meaning we have given Him a soul,\",\n",
    "    \"and 'I have breathed into him of My spirit.'\",\n",
    "    \"Those who have faith have a greater love for God.\",\n",
    "    \"I have hastened towards You, my Lord, to seek Your pleasure.\",\n",
    "    \"Although interpretation in words is clearer,\",\n",
    "     \"love without words is brighter.\"\n",
    "    ]\n",
    "\n",
    "# Create the TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the documents to get the TF-IDF matrix\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Get the feature names (terms)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the TF-IDF matrix to a dense format and print it\n",
    "tfidf_dense = tfidf_matrix.todense()\n",
    "print(\"TF-IDF Matrix:\\n\", tfidf_dense)\n",
    "\n",
    "# Print the feature names\n",
    "print(\"\\nFeature Names:\\n\", feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_The point here is that different words like conjunctions and verbs with various tenses are considered as part of the words. such as 'and' 'has' 'have' 'forgive' 'forgiving'_**\n",
    "\n",
    "### solve this problem\n",
    "\n",
    "To address the issue of different forms of words (like conjunctions, verbs in various tenses, etc.) being treated as separate terms, we can use techniques such as lemmatization and removing stopwords. Lemmatization reduces words to their base or root form, and removing stopwords eliminates common words that are typically not useful for feature extraction.\n",
    "\n",
    "Hereâ€™s a Python code example using nltk and sklearn to perform these preprocessing steps before applying TF-IDF:\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"If you love God, follow God so that\",\n",
    "    \"He may also love you and forgive your sins, \",\n",
    "    \"for He is Forgiving and Merciful.\",\n",
    "    \"God has given Him another creation, meaning we have given Him a soul,\",\n",
    "    \"and 'I have breathed into him of My spirit.'\",\n",
    "    \"Those who have faith have a greater love for God.\",\n",
    "    \"I have hastened towards You, my Lord, to seek Your pleasure.\",\n",
    "    \"Although interpretation in words is clearer,\",\n",
    "     \"love without words is brighter.\"\n",
    "    ]\n",
    "# Download NLTK resources (only need to run once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize the WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Get the list of stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lemmatize and remove stopwords\n",
    "    processed_tokens = [\n",
    "        lemmatizer.lemmatize(token.lower(), pos='v')  # Specify pos='v' for verbs\n",
    "        for token in tokens if token.lower() not in stop_words and token.isalnum()\n",
    "    ]\n",
    "    \n",
    "    # Join tokens back to string\n",
    "    return ' '.join(processed_tokens)\n",
    "\n",
    "# Preprocess the documents\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Create the TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the preprocessed documents to get the TF-IDF matrix\n",
    "tfidf_matrix = vectorizer.fit_transform(preprocessed_documents)\n",
    "\n",
    "# Get the feature names (terms)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the TF-IDF matrix to a dense format and print it\n",
    "tfidf_dense = tfidf_matrix.todense()\n",
    "\n",
    "# Print the feature names\n",
    "print(\"\\nFeature Names:\\n\", feature_names)\n",
    "```\n",
    "\n",
    "### Output is:\n",
    "Feature Names:\n",
    " ['also' 'although' 'another' 'breathe' 'brighter' 'clearer' 'creation'\n",
    " 'faith' 'follow' 'forgive' 'give' 'god' 'greater' 'hasten'\n",
    " 'interpretation' 'lord' 'love' 'may' 'mean' 'merciful' 'pleasure' 'seek'\n",
    " 'sin' 'soul' 'spirit' 'towards' 'without' 'word']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction from Image: \n",
    "\n",
    "**_Feature extraction_** from images involves transforming raw image data into a set of representative features that can be used for analysis or machine learning tasks. Some of its stages include:\n",
    "\n",
    "1. **Preprocessing**\n",
    "   Before extracting features, it's often necessary to preprocess the images to standardize them and remove noise. Common preprocessing steps include resizing, cropping, normalization, and noise reduction.\n",
    "2. **Feature Extraction Techniques**\n",
    "   There are various techniques for extracting features from images. Some popular methods include:\n",
    "\n",
    "- _Histogram of Oriented Gradients ([HOG](https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients))_\n",
    "  HOG computes the distribution of gradient orientations in localized portions of an image. It's commonly used for object detection and recognition tasks.\n",
    "- _Scale-Invariant Feature Transform ([SIFT](https://en.wikipedia.org/wiki/Scale-invariant_feature_transform))_\n",
    "  SIFT detects and describes local features in an image that are invariant to scale, rotation, and illumination changes. It's widely used in image matching and object recognition.\n",
    "- Convolutional Neural Networks ([CNNs](https://en.wikipedia.org/wiki/Convolutional_neural_network))\n",
    "  CNNs are deep learning models that automatically learn hierarchical features from images. They consist of convolutional layers that extract features at different levels of abstraction.\n",
    "\n",
    "3. **Feature Representation**\n",
    "   Once features are extracted, they need to be represented in a suitable format for analysis or machine learning algorithms. This could involve reshaping them into vectors or matrices.\n",
    "4. **Application**\n",
    "   Extracted features can be used for various tasks such as image classification, object detection, image retrieval, and content-based image retrieval.\n",
    "\n",
    "**Python Libraries for Image Feature Extraction**\n",
    "Popular Python *libraries for image feature extraction* include `OpenCV, scikit-image, and TensorFlow`.\n",
    "\n",
    "Here's a simple example using scikit-image to extract HOG features from an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hog\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m io, color\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "from skimage.feature import hog\n",
    "\n",
    "from skimage import io, color\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load an example image\n",
    "\n",
    "image = io.imread('IntroductionImages/Cheetah.jpg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "\n",
    "image_gray = color.rgb2gray(image)\n",
    "\n",
    "# Extract HOG features\n",
    "\n",
    "features, hog_image = hog(image_gray, visualize=True)\n",
    "\n",
    "# Display the original image and HOG features\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=True)\n",
    "\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(image, cmap=plt.cm.gray)\n",
    "\n",
    "ax[0].set_title('Original Image')\n",
    "\n",
    "ax[1].imshow(hog_image, cmap=plt.cm.gray)\n",
    "\n",
    "ax[1].set_title('HOG Features')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code loads an example image, converts it to grayscale, and extracts HOG features. It then displays the original image alongside the HOG features\n",
    "\n",
    "Another feature from image is histogram. The normalized histogram provides a probability distribution of pixel intensities in the grayscale image, highlighting the frequency of each intensity value across the entire image. following figure is Histogram of above cheetah.jpg\n",
    "\n",
    "Another feature extracted from the image is the ***histogram***. The normalized histogram provides a probability distribution of pixel intensities in the grayscale image, illustrating how frequently each intensity value occurs throughout the image. The x-axis represents the pixel intensity values, ranging from 0 (black) to 1 (white), while the y-axis shows the normalized frequency of each intensity value. To obtain a histogram of the image, the following code can be added:."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "import numpy as np\n",
    "hist, bins = np.histogram(image_gray, bins=256, range=(0, 1))\n",
    "\n",
    "# Normalize the histogram\n",
    "hist_normalized = hist / hist.sum()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows the normalized histogram for the image 'cheetah.jpg'.\n",
    "\n",
    "![Histogram of Image](IntroductionImages/Histogram_Feature.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the histogram can provide insights into the image's composition. Peaks in the histogram correspond to intensity values that occur frequently. In an image with a distinct target (like the cheetah) and background, the histogram might show two or more peaks. One peak could represent the intensity values of the target (cheetah), while another could represent the background (e.g., grass, sky). By analyzing these peaks, we can distinguish between different regions of the image. \n",
    "\n",
    "We can add code to detect **corners** in an image using the Harris Corner Detection method from the OpenCV library. This feature extraction technique identifies points in the image where the intensity changes significantly in multiple directions, which typically corresponds to corners. Main change of code:\n",
    "```python\n",
    "import cv2\n",
    "# Detect corners using Harris Corner Detection\n",
    "image_gray_cv2 = (image_gray * 255).astype(np.uint8)  # Convert to uint8 for OpenCV\n",
    "corners = cv2.cornerHarris(image_gray_cv2, blockSize=2, ksize=3, k=0.04)\n",
    "corners_dilated = cv2.dilate(corners, None)  # Dilate to mark the corners\n",
    "image_with_corners = np.copy(image)\n",
    "image_with_corners[corners_dilated > 0.01 * corners_dilated.max()] = [255, 0, 0]  # Mark corners in red\n",
    "```\n",
    "\n",
    "![Corner](IntroductionImages/CornerFaeture.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to Intro. of PR](..//Introduction/Introduction_1.ipynb#Table-of-Introduction-in-PR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".M_HomePage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}